import pyarrow.parquet as pq
import numpy as np
import pickle
import faiss
import os

# 1. Param√®tres
PARQUET_FILE = "tindle_embeddings.parquet"
FAISS_INDEX_FILE = "tindle_index.faiss"
EMBED_DIM = None          # sera d√©tect√© automatiquement plus bas
FAISS_INDEX_FACTORY = "IVF4096,Flat"   # ou "Flat" pour un index exact

# 2. Charger les donn√©es depuis Parquet
print("‚û°Ô∏è Lecture du Parquet...")
table = pq.read_table(PARQUET_FILE, columns=["id", "embedding"])
ids = table.column("id").to_pylist()
embeddings = table.column("embedding")

# If embeddings are stored as Arrow FixedSizeList or List of float32, this will work:
xb = np.vstack([np.array(e.as_py(), dtype="float32") for e in embeddings])
n, d = xb.shape
EMBED_DIM = d
print(f"‚úîÔ∏è {n} vecteurs de dimension {d}")

print(embeddings[0])
print(type(embeddings[0]))

for i in range(5):
    print(embeddings[i], type(embeddings[i]))

# 3. Cr√©er l'index FAISS
#    - IVF (Inverted File) pour gros volume ou Flat pour exact
print("‚û°Ô∏è Cr√©ation de l'index FAISS...")
index = faiss.index_factory(d, FAISS_INDEX_FACTORY, faiss.METRIC_L2)

# Si on utilise un IVF on doit entra√Æner l'index sur les donn√©es
if not index.is_trained:
    print("üìö Entra√Ænement de l'index‚Ä¶")
    index.train(xb)

# 4. Alimenter l'index
print("‚û°Ô∏è Ajout des vecteurs √† l'index‚Ä¶")
index.add(xb)  # on pourrait aussi faire add_with_ids pour custom ids

# 5. Sauvegarder l'index et la liste d'IDs
print(f"‚û°Ô∏è Sauvegarde de l'index dans `{FAISS_INDEX_FILE}`‚Ä¶")
faiss.write_index(index, FAISS_INDEX_FILE)

# Pour r√©utiliser plus tard, tu charge dans un dict ou un fichier √† part
with open("tindle_ids.pkl", "wb") as f:
    pickle.dump(ids, f)

print("‚úÖ Index FAISS pr√™t et sauvegard√© !")